accum_freq: 1
aug_cfg: {}
batch_size: 128
beta1: 0.9
beta2: 0.98
checkpoint_path: /mmfs1/gscratch/krishna/arnabk1/mayank_clip_mrl/scripts/logs/mrl_clip_b256_accum_1_ep40_diffLogitScale_D032524_w1_gpu8_wkrs2/checkpoints
coca_caption_loss_weight: 2.0
coca_contrastive_loss_weight: 1.0
copy_codebase: False
csv_caption_key: title
csv_img_key: filepath
csv_separator: 	
dataset_resampled: False
dataset_type: webdataset
ddp_static_graph: False
debug: False
delete_previous_checkpoint: False
device: cuda:0
dist_backend: nccl
dist_url: env://
distill: False
distill_model: None
distill_pretrained: None
distributed: True
epochs: 40
epochs_cooldown: None
eps: 1e-06
force_custom_text: False
force_image_size: None
force_mrl_loss: True
force_patch_dropout: None
force_quick_gelu: False
gather_with_grad: True
grad_checkpointing: False
grad_clip_norm: None
horovod: False
image_mean: None
image_std: None
imagenet_v2: None
imagenet_val: /gscratch/krishna/arnabk1/root/val/
local_loss: True
local_rank: 0
lock_image: False
lock_image_freeze_bn_stats: False
lock_image_unlocked_groups: 0
lock_text: False
lock_text_freeze_layer_norm: False
lock_text_unlocked_layers: 0
log_every_n_steps: 100
log_level: 20
log_local: False
log_path: /mmfs1/gscratch/krishna/arnabk1/mayank_clip_mrl/scripts/logs/mrl_clip_b256_accum_1_ep40_diffLogitScale_D032524_w1_gpu8_wkrs2/out.log
logs: /mmfs1/gscratch/krishna/arnabk1/mayank_clip_mrl/scripts/logs/
lr: 0.0005
lr_cooldown_end: 0.0
lr_cooldown_power: 1.0
lr_scheduler: cosine
model: ViT-B-16
mrl_dim_to_consider: [768, 384, 192, 96, 48]
mrl_loss_weights: [1.0, 1.0, 1.0, 1.0, 1.0]
name: mrl_clip_b256_accum_1_ep40_diffLogitScale_D032524_w1_gpu8_wkrs2
no_set_device_rank: False
precision: amp
pretrained: 
pretrained_image: False
rank: 0
remote_sync: None
remote_sync_frequency: 300
remote_sync_protocol: s3
report_to: wandb
resume: None
save_frequency: 1
save_most_recent: False
seed: 42
skip_scheduler: False
tensorboard: False
tensorboard_path: 
torchscript: False
trace: False
train_data: /gscratch/krishna/chenhaoz/IL/FDT/data/cc3m/{00000..00032}.tar
train_data_upsampling_factors: None
train_num_samples: 3308333
use_bn_sync: False
val_data: None
val_frequency: 1
val_num_samples: None
wandb: True
wandb_notes: 
wandb_project_name: mrl_clip_training
warmup: 4000
wd: 0.2
workers: 2
world_size: 8
zeroshot_frequency: 2
